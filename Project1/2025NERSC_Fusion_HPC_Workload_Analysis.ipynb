{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0daa710a",
   "metadata": {},
   "source": [
    "# Module: Powering the Future — HPC Workload and Performance Analysis in Fusion Energy Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09f43cb",
   "metadata": {},
   "source": [
    "## 🌟 Introduction\n",
    "\n",
    "Welcome to the **Fusion Energy & High-Performance Computing (HPC)** module — an exciting journey into the technologies powering the **future of clean energy** and scientific discovery! ⚛️💻\n",
    "\n",
    "Fusion energy — the process that powers the Sun — promises a virtually limitless and sustainable source of energy for our planet. Researchers across the globe, including at leading **U.S. Department of Energy (DOE)** laboratories, are working to bring this stellar energy source to Earth. \n",
    "\n",
    "However, harnessing fusion isn't easy. It involves **extreme conditions**, **complex physics**, and **massive data volumes**. That's where **High-Performance Computing (HPC)** comes in. DOE labs like [LLNL](https://www.llnl.gov/), [ORNL](https://www.ornl.gov/), and [PPPL](https://www.pppl.gov/) rely on some of the **fastest supercomputers in the world** to simulate plasma behavior, optimize reactor designs, and process experimental data.\n",
    "\n",
    "---\n",
    "\n",
    "### 🌐 Why Fusion + HPC?\n",
    "\n",
    "- 🔬 **Modeling extreme plasma physics** — where temperatures exceed millions of degrees.\n",
    "- 🧠 **Training AI/ML models** to predict reactor behavior.\n",
    "- ⚙️ **Designing and testing reactor materials** under intense conditions.\n",
    "- 📈 **Analyzing massive datasets** from experiments and simulations.\n",
    "\n",
    "---\n",
    "\n",
    "### 🖼️ Visual: Fusion & Supercomputing\n",
    "\n",
    "![Fusion Energy](https://upload.wikimedia.org/wikipedia/commons/thumb/9/98/NIF_target_chamber.jpg/800px-NIF_target_chamber.jpg)\n",
    "*Image: Target chamber of the National Ignition Facility (NIF), a fusion experiment at LLNL.*  \n",
    "*Source: Wikimedia Commons*\n",
    "\n",
    "---\n",
    "\n",
    "By the end of this module, you'll gain insight into how **HPC accelerates breakthroughs** in fusion research — and how your future work can contribute to this critical mission.\n",
    "\n",
    "Let’s ignite the stars here on Earth — together. 🌟🌍\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2ea518",
   "metadata": {},
   "source": [
    "## 💡 Goals of this Module\n",
    "\n",
    "This 3-day project module is designed to help you explore how **fusion energy research** and **high-performance computing** intersect in real-world DOE applications.\n",
    "\n",
    "By the end of this module, you will be able to:\n",
    "\n",
    "🔹 **Explain** the fundamentals of fusion energy and how it differs from fission.  \n",
    "🔹 **Understand** why HPC systems are essential for modeling fusion reactions.  \n",
    "🔹 **Analyze** synthetic fusion workload data using Python and common scientific libraries.  \n",
    "🔹 **Visualize** patterns in computational demand across DOE fusion experiments.  \n",
    "🔹 **Present findings** in a short group report simulating a DOE project debrief.\n",
    "\n",
    "This project combines **scientific computing**, **data analysis**, and **real-world DOE mission contexts**, giving you a unique opportunity to contribute to one of the most important scientific challenges of our time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84639a50",
   "metadata": {},
   "source": [
    "## 🖥️ HPC Systems Used for Fusion Research\n",
    "\n",
    "To unlock the secrets of fusion, DOE researchers rely on some of the world’s most advanced supercomputers. These systems simulate plasma dynamics, materials stress, and energy confinement in complex fusion devices like **tokamaks** and **laser-based inertial confinement reactors**.\n",
    "\n",
    "Here are some notable HPC systems and how they contribute to fusion:\n",
    "\n",
    "### 🔷 NERSC — Perlmutter (LBNL)\n",
    "- Used for plasma simulation, turbulence modeling, and data analysis.\n",
    "- Houses both CPU and GPU nodes, ideal for parallel workloads.\n",
    "\n",
    "### 🔷 Summit (ORNL)\n",
    "- Powered deep learning efforts in fusion forecasting and control.\n",
    "- Supported research into magnetic confinement and MHD (magnetohydrodynamic) stability.\n",
    "\n",
    "### 🔷 Frontier (ORNL)\n",
    "- World’s first exascale supercomputer (as of 2024).\n",
    "- Enables multi-scale modeling of fusion materials and magnetic fields.\n",
    "\n",
    "### 🔷 Cori (LBNL) *(Retired but historically important)*\n",
    "- Served fusion researchers developing scalable codes like **XGC** and **GTC**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍🔬 Why HPC is Essential for Fusion:\n",
    "- Fusion involves **nonlinear, multi-physics phenomena**.\n",
    "- Requires **high spatial and temporal resolution** to simulate plasma behavior.\n",
    "- Real-time data from experiments can produce **terabytes per run**.\n",
    "- HPC allows researchers to test **thousands of reactor configurations** virtually.\n",
    "\n",
    "---\n",
    "\n",
    "📎 *Further Reading:*\n",
    "- [Fusion Energy Sciences at DOE](https://science.osti.gov/fes)\n",
    "- [NERSC Science Highlights](https://www.nersc.gov/news-publications/science-highlights/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5811c315",
   "metadata": {},
   "source": [
    "## 📊 Dataset Overview\n",
    "\n",
    "In this notebook, we’ll use a **synthetic dataset** that mimics real-world fusion HPC workloads submitted to systems like NERSC’s **Perlmutter**. This data simulates what a workload trace might look like over time across multiple DOE experiments.\n",
    "\n",
    "### 📁 Dataset Columns:\n",
    "- `JobID`: Unique identifier for each submitted job.\n",
    "- `Project`: Fusion project or facility (e.g., DIII-D, NSTX-U, NIF).\n",
    "- `SubmissionTime`: Timestamp of job submission.\n",
    "- `StartTime`, `EndTime`: Run time markers.\n",
    "- `NodesRequested`: Number of nodes requested.\n",
    "- `RuntimeMinutes`: Duration of the job.\n",
    "- `JobType`: Categorized workload (e.g., simulation, post-processing, ML).\n",
    "- `Facility`: Computing system used.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 Project Use:\n",
    "You will use this dataset to:\n",
    "- Analyze **resource usage trends**.\n",
    "- Investigate **which projects use HPC most intensively**.\n",
    "- Compare **job types and facilities**.\n",
    "- Explore **optimization strategies** and implications for scheduling.\n",
    "\n",
    "📌 *Note:* The data has been anonymized and synthesized to protect institutional privacy but reflects real usage patterns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf9cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Synthetic data sample\n",
    "data = pd.DataFrame({\n",
    "    'Application': ['GTC', 'XGC', 'TRANSP', 'GTC', 'XGC', 'GENE'],\n",
    "    'Cores': [512, 1024, 768, 2048, 1536, 1024],\n",
    "    'Runtime_hours': [5.2, 3.1, 6.0, 10.5, 7.2, 4.4],\n",
    "    'Power_kW': [130, 210, 180, 400, 320, 150]\n",
    "})\n",
    "data['Energy_kWh'] = data['Runtime_hours'] * data['Power_kW']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e66721d",
   "metadata": {},
   "source": [
    "## 📈 Energy Consumption per Application\n",
    "\n",
    "Energy usage is a critical factor in HPC operations — especially when considering the **cost and carbon footprint** of running large-scale fusion simulations.\n",
    "\n",
    "In this section, we will explore:\n",
    "- How different fusion applications consume energy,\n",
    "- The computational cost per job type,\n",
    "- Potential opportunities for **energy-efficient computing**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔬 Simulated Applications\n",
    "Here are some fusion-related workloads you might see:\n",
    "- `PlasmaSim`: Models plasma turbulence and instabilities.\n",
    "- `FusionAI`: Trains ML models on reactor sensor data.\n",
    "- `ReactMat`: Simulates material degradation under neutron flux.\n",
    "- `BeamOpt`: Optimizes beam configurations for inertial confinement.\n",
    "- `DataPost`: Post-processing of experiment output.\n",
    "\n",
    "Each application has an associated **energy footprint**, estimated using:\n",
    "```\n",
    "Energy (kWh) = RuntimeMinutes × PowerPerNode × NodesRequested ÷ 60\n",
    "```\n",
    "\n",
    "We’ll use simulated `PowerPerNode` values (in kW) to compute energy for each job and **visualize usage per application**.\n",
    "\n",
    "📊 *Your Task:* Group jobs by application and compute total and average energy consumption. Then, identify the **most and least energy-efficient apps**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873db7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Application', y='Energy_kWh', data=data)\n",
    "plt.title('Energy Usage by Fusion Application')\n",
    "plt.ylabel('Total Energy (kWh)')\n",
    "plt.xlabel('Application')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2363ddd4",
   "metadata": {},
   "source": [
    "## 🧠 Questions for Reflection\n",
    "\n",
    "As you analyze the fusion HPC workloads, use these questions to guide your thinking and shape your findings:\n",
    "\n",
    "### 🔎 Scientific Insight\n",
    "- What types of fusion workloads dominate HPC usage?\n",
    "- Which experiments appear to be the most resource-intensive?\n",
    "\n",
    "### ⚡ Energy Awareness\n",
    "- Which applications consume the most energy per job?\n",
    "- Are there apps that could benefit from GPU acceleration or code optimization?\n",
    "\n",
    "### 💡 Efficiency Strategies\n",
    "- If you were designing a job scheduler, how would you prioritize jobs?\n",
    "- What trade-offs might exist between runtime, energy, and scientific output?\n",
    "\n",
    "### 🌱 Sustainability Lens\n",
    "- How can HPC centers reduce energy usage without compromising science?\n",
    "- What role might **renewable energy** and **green computing** play in DOE labs of the future?\n",
    "\n",
    "Use these questions to prepare your **final group reflections** or reports at the end of Day 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60ad034",
   "metadata": {},
   "source": [
    "## 🔍 Efficiency Metrics\n",
    "\n",
    "Understanding how well compute resources are used is central to optimizing both **cost** and **scientific throughput**.\n",
    "\n",
    "We’ll define and calculate several key metrics:\n",
    "\n",
    "---\n",
    "\n",
    "### 🔧 Runtime Efficiency\n",
    "Measures how effectively the allocated nodes are used:\n",
    "```\n",
    "RuntimeEfficiency = (EndTime - StartTime) / (AllocatedTime)\n",
    "```\n",
    "High efficiency means minimal idle time.\n",
    "\n",
    "---\n",
    "\n",
    "### ⚡ Energy Efficiency (kWh per core-hour)\n",
    "```\n",
    "EnergyPerCoreHour = EnergyConsumed / (RuntimeMinutes × CoresPerNode / 60)\n",
    "```\n",
    "Lower values indicate better utilization of compute energy.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 ML Efficiency (optional)\n",
    "If your dataset includes `FusionAI` jobs, you may compare:\n",
    "- **Accuracy per Watt**\n",
    "- **Training Time per kWh**\n",
    "\n",
    "---\n",
    "\n",
    "📌 *Action:* Compute these metrics across job types and identify which workloads show:\n",
    "- The **best resource utilization**, and\n",
    "- The **highest energy efficiency**.\n",
    "\n",
    "Use this to make **data-driven recommendations** to a fictional HPC director on Day 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f1ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Core_Hours'] = data['Cores'] * data['Runtime_hours']\n",
    "data['kWh_per_CoreHour'] = data['Energy_kWh'] / data['Core_Hours']\n",
    "data[['Application', 'Core_Hours', 'kWh_per_CoreHour']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370e2edc",
   "metadata": {},
   "source": [
    "## 📉 Visualization: Energy per Core-Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871ffbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Application', y='kWh_per_CoreHour', data=data)\n",
    "plt.title('Energy per Core-Hour by Application')\n",
    "plt.ylabel('kWh / Core-Hour')\n",
    "plt.xlabel('Application')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7c6c8c",
   "metadata": {},
   "source": [
    "## 📌 Takeaways and Implications\n",
    "- Some applications scale more efficiently than others.\n",
    "- High energy cost per core-hour may indicate poor scaling or I/O bottlenecks.\n",
    "- These insights help optimize batch submission strategies and resource allocation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11148b3",
   "metadata": {},
   "source": [
    "## 🧪 Challenge Exercise\n",
    "Use this data to:\n",
    "1. Identify the most efficient application by core-hour.\n",
    "2. Suggest how runtime or core count could be adjusted for better energy efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba678cc",
   "metadata": {},
   "source": [
    "## 📚 Further Resources\n",
    "- [NERSC Fusion Workloads](https://www.nersc.gov/science/fusion-energy/)\n",
    "- [Energy-Aware Scheduling Survey (Kocot et al., 2023)](https://www.mdpi.com/1996-1073/16/2/890)\n",
    "- [Top500 and Green500 Rankings](https://www.top500.org/lists/green500/2023/06/)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
